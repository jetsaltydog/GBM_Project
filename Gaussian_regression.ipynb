{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sklearn.gaussian_process as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "ID = data['id']\n",
    "\n",
    "#Drop unnecessary columns\n",
    "data = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['log_loss'] = np.log(data['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_size = 0.2\n",
    "stepsize = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_b = [] #time\n",
    "MAE_b = [] #mean absolute error\n",
    "N_b = [] #data\n",
    "\n",
    "#Drop unnecessary columns\n",
    "train = train.iloc[:,1:]\n",
    "train['log_loss'] = np.log(train['loss'])\n",
    "\n",
    "n_data = 10000\n",
    "\n",
    "cont_X = train.iloc[0:n_data, 117:131]\n",
    "cat_X = train.iloc[0:n_data, 1:117]\n",
    "X = train.iloc[0:n_data, :131]\n",
    "Y = train.iloc[0:n_data, 131:]\n",
    "log_Y = data.iloc[0:n_data, 131:132]\n",
    "\n",
    "dummies_X = np.array(pd.get_dummies(cat_X))\n",
    "new_X = np.c_[dummies_X, cont_X]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, log_Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "y_train = y_train.iloc[:,0]\n",
    "    \n",
    "#kernel = gp.kernels.ConstantKernel() * gp.kernels.RBF()\n",
    "#1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "\n",
    "model = gp.GaussianProcessRegressor()#kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#params = model.kernel_.get_params()\n",
    "y_pred, std = model.predict(X_test, return_std=True)\n",
    "#print(y_pred)\n",
    "\n",
    "mae = mean_absolute_error(np.exp(y_pred), np.exp(y_test))\n",
    "MAE_b.append(mae)\n",
    "print('mae',mae)\n",
    "Time = time.time() - start_time\n",
    "T_b.append(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (<ipython-input-1-ba6283ae5aa4>, line 108)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ba6283ae5aa4>\"\u001b[1;36m, line \u001b[1;32m108\u001b[0m\n\u001b[1;33m    T_b.append(Time)\u001b[0m\n\u001b[1;37m                    \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "ID = data['id']\n",
    "\n",
    "#Drop unnecessary columns\n",
    "data = data.iloc[:,1:]\n",
    "data['log_loss'] = np.log(data['loss'])\n",
    "\n",
    "stepsize = 10000\n",
    "\n",
    "stepsize = 10000\n",
    "\n",
    "#Base\n",
    "\n",
    "T_b = [] #time\n",
    "MAE_b = [] #mean absolute error\n",
    "N_b = [] #data\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "for i in range(1, 19):\n",
    "    print(i)\n",
    "    n_data = i*stepsize\n",
    "    N_b.append(n_data)\n",
    "    \n",
    "    cont_X = data.iloc[0:n_data, 116:130]\n",
    "    cat_X = data.iloc[0:n_data, 0:116]\n",
    "    X = data.iloc[0:n_data, :130]\n",
    "\n",
    "    Y = data.iloc[0:n_data, 130:131]\n",
    "    \n",
    "    dummies_X = np.array(pd.get_dummies(cat_X))\n",
    "    new_X = np.c_[dummies_X, cont_X]\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_X, Y,     test_size=test_size, random_state=seed)\n",
    "\n",
    "    y_train = y_train.iloc[:,0]\n",
    "    \n",
    "    kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\n",
    "    model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    params = model.kernel_.get_params()\n",
    "    y_pred, std = model.predict(X_test, return_std=True)\n",
    "    print(y_pred)\n",
    "\n",
    "    mae = mean_absolute_error(y_pred, y_test)\n",
    "    MAE_b.append(mae)\n",
    "    print('mae',mae)\n",
    "    Time = time.time() - start_time\n",
    "    T_b.append(Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
